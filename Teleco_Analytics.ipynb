{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('script')\n",
    "from script import dbconn\n",
    "pgconn = dbconn.db_connection_psycopg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\o876\\Desktop\\User-Analytics-in-telecommunication-industry\\script\\dbconn.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = sqlio.read_sql_query(sql,pgconn)\n"
     ]
    }
   ],
   "source": [
    "# Fectching data from the postgreSql database and put the value on raw_df\n",
    "raw_df = dbconn.db_read_table_psycopg(pgconn,'xdr_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Overview analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the top 10 handsets used by the customers.\n",
    "# Count handset usage\n",
    "handset_counts = raw_df.groupby(['Handset Manufacturer', 'Handset Type']).size().reset_index(name='Count')\n",
    "\n",
    "# Sort the results\n",
    "sorted_handsets = handset_counts.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Select the top 10 handsets\n",
    "top_10_handsets = sorted_handsets.head(10)\n",
    "\n",
    "# Print the top 10 handsets\n",
    "print(top_10_handsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying Top 3 handset manufacturers\n",
    "manufacturer_counts = raw_df['Handset Manufacturer'].value_counts().reset_index()\n",
    "manufacturer_counts.columns = ['Handset Manufacturer', 'Count']\n",
    "\n",
    "# Sort the results\n",
    "sorted_manufacturers = manufacturer_counts.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Select the top 3 handset manufacturers\n",
    "top_3_manufacturers = sorted_manufacturers.head(3)\n",
    "\n",
    "# Print the top 3 handset manufacturers\n",
    "print(top_3_manufacturers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top 5 handsets per top 3 handset manufacturer\n",
    "# Count handset manufacturers and types\n",
    "manufacturer_type_counts = raw_df.groupby(['Handset Manufacturer', 'Handset Type']).size().reset_index(name='Count')\n",
    "\n",
    "# Sort the results within each manufacturer\n",
    "sorted_manufacturer_types = manufacturer_type_counts.groupby('Handset Manufacturer').apply(lambda x: x.nlargest(5, 'Count')).reset_index(drop=True)\n",
    "\n",
    "# Print the top 5 handsets per top 3 handset manufacturers\n",
    "top_3_manufacturers = sorted_manufacturer_types['Handset Manufacturer'].unique()[:3]\n",
    "\n",
    "for manufacturer in top_3_manufacturers:\n",
    "    print(f\"Top 5 handsets for {manufacturer}:\")\n",
    "    manufacturer_handsets = sorted_manufacturer_types[sorted_manufacturer_types['Handset Manufacturer'] == manufacturer]\n",
    "    print(manufacturer_handsets)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying users’ behaviour on those Applications / Social Media, Google, Email, Youtube, Netflix, Gaming, Other.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the number of xDR sessions per user\n",
    "sessions_per_user = raw_df.groupby('MSISDN/Number')['Bearer Id'].count()\n",
    "print(sessions_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the session duration per user\n",
    "session_duration_per_user = raw_df.groupby('MSISDN/Number')['Dur. (ms)'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(session_duration_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the total download (Dl) and upload data per user\n",
    "total_data_per_user = raw_df.groupby('MSISDN/Number')[['Total DL (Bytes)', 'Total UL (Bytes)']].sum()\n",
    "\n",
    "# Display the result\n",
    "print(total_data_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of application columns\n",
    "applications = ['Social Media', 'Google', 'Email', 'Youtube', 'Netflix', 'Gaming', 'Other']\n",
    "\n",
    "# Aggregate the total data volume per user and application\n",
    "total_data_per_user_app = raw_df.groupby('MSISDN/Number')[[col + ' DL (Bytes)' for col in applications] + [col + ' UL (Bytes)' for col in applications]].sum()\n",
    "\n",
    "# Display the result\n",
    "print(total_data_per_user_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanatory Data Analysis | EDA\n",
    "# Treat all missing values and outliers in the dataset by replacing by the mean of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Identifying and Treating missing value \n",
    "missing_values = raw_df.isna().sum()\n",
    "print (missing_values)\n",
    "\n",
    "for column in missing_values.index:\n",
    "    if missing_values[column] > 0:\n",
    "        mean_value = str(raw_df[column].mean())\n",
    "        raw_df[column] = raw_df[column].fillna(mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the basic metrics (mean, median, etc) from the dataset\n",
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a Non-Graphical Univariate Analysis by computing dispersion parameters for each quantitative variable.\n",
    "\n",
    "quantitative_variables = []\n",
    "\n",
    "# Iterate over each column in the dataset to find the quantitative variable\n",
    "for column in raw_df.columns:   \n",
    "    if raw_df[column].dtype in [int, float]:\n",
    "        quantitative_variables.append(column)\n",
    "\n",
    "# Solution: By calculating the range or Difference b/n max and min value in each variable\n",
    "for column_name in quantitative_variables:\n",
    "    column_data = raw_df[column_name]\n",
    "    data_range = column_data.max() - column_data.min()\n",
    "    print(\"Range of\", column_name, \":\", data_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a Graphical Univariate Analysis by identifying the most suitable plotting options for each variable and interpret your findings.\n",
    "# column_name = 'Avg RTT DL (ms)'\n",
    "clean_Data = raw_df.dropna()\n",
    "column_names = clean_Data.columns\n",
    "\n",
    "for column_name in column_names:\n",
    "    column_data = clean_Data[column_name]    \n",
    "    plt.hist(column_data, bins=10)\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of ' + column_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable transformations\n",
    "# Segment the users into top five decile classes based on the total duration for all sessions and compute the total data (DL+UL) per decile class. \n",
    "\n",
    "# Calculate the total duration for all sessions for each user\n",
    "user_total_duration = raw_df.groupby('MSISDN/Number')['Dur. (ms)'].sum()\n",
    "\n",
    "# Segment users into decile classes\n",
    "user_deciles = pd.qcut(user_total_duration, q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Compute the total data (DL+UL) per decile class\n",
    "data_per_decile = raw_df.groupby(user_deciles)[['Total DL (Bytes)', 'Total UL (Bytes)']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis – compute a correlation matrix for the following variables and interpret your findings: Social Media data, Google data, Email data, Youtube data, Netflix data, Gaming data, Other data \n",
    "# Select the columns for correlation analysis\n",
    "columns = [\n",
    "    'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
    "    'Google DL (Bytes)', 'Google UL (Bytes)',\n",
    "    'Email DL (Bytes)', 'Email UL (Bytes)',\n",
    "    'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
    "    'Netflix DL (Bytes)', 'Netflix UL (Bytes)',\n",
    "    'Gaming DL (Bytes)', 'Gaming UL (Bytes)',\n",
    "    'Other DL (Bytes)', 'Other UL (Bytes)'\n",
    "]\n",
    "\n",
    "# Create a subset dataframe with the selected columns\n",
    "subset_df = raw_df[columns]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = subset_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
